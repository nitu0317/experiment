{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988ffc60-23ba-47b8-a890-ddaaa0020c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "from matplotlib import pyplot as plt\n",
    "from gurobipy import *\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import collections\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b693754-34c2-4b21-92c8-08dcfed2e123",
   "metadata": {},
   "source": [
    "## Estimation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "793fdcd8-e11d-4166-8ee3-817776c11d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## linear regression\n",
    "def linear_regress(Xs, Rs, reg):\n",
    "    X_train, R_train = [], []\n",
    "    for j in range(J):\n",
    "        tmp = np.concatenate((Xs[j], np.zeros((len(Xs[j]), (d+1) * (J-1)))), axis=1)\n",
    "        if j >= 1:\n",
    "            for n in range(len(Rs[j])):\n",
    "                tmp[n][d + (j-1) * (d+1)] = 1\n",
    "                tmp[n][d + (j-1) * (d+1) + 1: d + j * (d+1)] = Xs[j][n]\n",
    "        \n",
    "        X_train.append(tmp)\n",
    "        R_train.append(Rs[j])\n",
    "    \n",
    "    X_trains = np.concatenate(X_train)\n",
    "    R_trains = np.concatenate(R_train)\n",
    "    \n",
    "    if reg == 'ordinal':\n",
    "        lr, cv_loss = ols(X_train, R_train)\n",
    "        return lr.intercept_, lr.coef_, cv_loss\n",
    "    elif reg == 'ridge':\n",
    "        m = linear_model.RidgeCV(cv=10)\n",
    "        lr = m.fit(X_trains, R_trains)\n",
    "    elif reg == 'lasso':\n",
    "        m = linear_model.LassoCV(cv=10)\n",
    "        lr = m.fit(X_trains, R_trains)  \n",
    "    elif reg == 'new':\n",
    "        res, cv_loss = new(X_train, R_train)\n",
    "        \n",
    "        return res[0], res[1:], cv_loss\n",
    "        \n",
    "    return lr.intercept_, lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "cf128bf5-eb5e-4c37-b866-64f6e4f6a223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def new(X_train, R_train): \n",
    "    F = 10\n",
    "    p = (0, 0.5, 0.5)\n",
    "    \n",
    "    X_train_0 = np.concatenate((np.reshape(np.ones(len(X_train[0])), (-1, 1)), X_train[0]), axis=1)\n",
    "    X_train_1 = np.concatenate((np.reshape(np.ones(len(X_train[1])), (-1, 1)), X_train[1]), axis=1)\n",
    "    X_train_2 = np.concatenate((np.reshape(np.ones(len(X_train[2])), (-1, 1)), X_train[2]), axis=1)\n",
    "    \n",
    "    X_fold = {0: np.split(X_train_0, 10), 1: np.split(X_train_1, 10), 2: np.split(X_train_2, 10)}\n",
    "    R_fold = {0: np.split(R_train[0], 10), 1: np.split(R_train[1], 10), 2: np.split(R_train[2], 10)}\n",
    "    \n",
    "    coefs = [0, 0.02, 0.04, 0.06, 0.08, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.6, 0.7, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2, 10, 20]\n",
    "#     coefs = [0.5, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 30]\n",
    "    coefs_loss = []\n",
    "    for coef in coefs:  \n",
    "        Loss = 0\n",
    "        for k in range(F):\n",
    "            R_valid = np.concatenate([R_fold[j][k] for j in range(J)])\n",
    "            X_valid = np.concatenate([X_fold[j][k] for j in range(J)])\n",
    "\n",
    "            R_input = np.concatenate([R_fold[j][l] for j in range(J) for l in range(F) if l != k])\n",
    "            X_input = np.concatenate([X_fold[j][l] for j in range(J) for l in range(F) if l != k])\n",
    "\n",
    "            beta = solve_convex(X_input, R_input, coef, p)\n",
    "\n",
    "            loss = np.sum((np.dot(X_valid, beta) - R_valid) ** 2)\n",
    "            Loss += loss\n",
    "        coefs_loss.append(Loss / (J * N))\n",
    "    \n",
    "    cv_coef = coefs[np.argmin(coefs_loss)]\n",
    "    cv_loss = np.min(coefs_loss) \n",
    "    print(cv_coef)\n",
    "    print(cv_loss)\n",
    "    beta = solve_convex(np.concatenate([X_train_0, X_train_1, X_train_2]), np.concatenate(R_train), cv_coef, p)\n",
    "\n",
    "    return beta, coefs_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aef74e6-5661-4de5-9816-0f7229a2be95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ols(X_train, R_train): \n",
    "    F = 10\n",
    "    X_fold = {0: np.split(X_train[0], F), 1: np.split(X_train[1], F), 2: np.split(X_train[2], F)}\n",
    "    R_fold = {0: np.split(R_train[0], F), 1: np.split(R_train[1], F), 2: np.split(R_train[2], F)}\n",
    "\n",
    "    Loss = 0\n",
    "    for k in range(F):\n",
    "        R_valid = np.concatenate([R_fold[j][k] for j in range(J)])\n",
    "        X_valid = np.concatenate([X_fold[j][k] for j in range(J)])\n",
    "\n",
    "        R_input = np.concatenate([R_fold[j][l] for j in range(J) for l in range(F) if l != k])\n",
    "        X_input = np.concatenate([X_fold[j][l] for j in range(J) for l in range(F) if l != k])\n",
    "\n",
    "        lr = linear_model.LinearRegression().fit(X_input, R_input) \n",
    "        loss = np.sum((lr.intercept_ + np.dot(X_valid, lr.coef_) - R_valid) ** 2)\n",
    "        Loss += loss\n",
    "    \n",
    "    m = linear_model.LinearRegression()\n",
    "    lr = m.fit(np.concatenate(X_train), np.concatenate(R_train))\n",
    "    cv_loss = Loss / (J * N)\n",
    "    print(cv_loss)\n",
    "    return lr, cv_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "055e7940-e761-4108-baaa-c7baa3c5bee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def solve_convex(X_input, R_input, _lambda, _prob):\n",
    "    beta = cp.Variable((d + 1) * J)\n",
    "    loss = cp.sum_squares(X_input @ beta - R_input) / len(R_input)\n",
    "    \n",
    "    regularizer = 0\n",
    "    for j in range(J):\n",
    "#         if j >= 1:\n",
    "#             for i in range(d):\n",
    "#                 regularizer += (sigma[i] * (beta[i+1+j*(d+1)])) ** 2 * _prob[j]        \n",
    "        \n",
    "        if j >= 1:\n",
    "            regularizer += cp.quad_form(beta[1+j*(d+1):(j+1)*(d+1)], Sigma) * _prob[j]    \n",
    "    \n",
    "#         if j == 0:\n",
    "#             for i in range(d):\n",
    "#                 regularizer += (sigma[i] * beta[i+1]) ** 2 * _prob[j]\n",
    "#         elif j >= 1:\n",
    "#             for i in range(d):\n",
    "#                 regularizer += (sigma[i] * (beta[i+1] + beta[i+1+j*(d+1)])) ** 2 * _prob[j]\n",
    "        \n",
    "#         if j == 0:\n",
    "#             regularizer += cp.quad_form(beta[1:d+1], Sigma) * _prob[j]\n",
    "#         else:\n",
    "#             regularizer += cp.quad_form(beta[1:d+1] + beta[1+j*(d+1):(j+1)*(d+1)], Sigma) * _prob[j]\n",
    "           \n",
    "                \n",
    "    prob = cp.Problem(cp.Minimize(loss + regularizer * _lambda))\n",
    "    prob.solve()\n",
    "    \n",
    "    return beta.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41850f31-6903-4a1e-bb98-a712b263861e",
   "metadata": {},
   "source": [
    "## Optimization Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86067260-2bf1-4438-a06e-103f80a27efa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inner_opt_soc(Z, Gamma, gamma):\n",
    "    m = Model()\n",
    "    m.setParam('LogToConsole', 0)\n",
    "    \n",
    "    Beta_0 = m.addVars((j for j in range(J)), vtype=GRB.CONTINUOUS, lb=-GRB.INFINITY, ub=GRB.INFINITY)\n",
    "    Beta_1 = m.addVars(((j, i) for j in range(J) for i in range(d)), vtype=GRB.CONTINUOUS, lb=-GRB.INFINITY, ub=GRB.INFINITY)\n",
    "    Delta = m.addVars(((j, n) for j in range(J) for n in range(len(Xs[j]))), vtype=GRB.CONTINUOUS, lb=-GRB.INFINITY, ub=GRB.INFINITY)\n",
    "    \n",
    "    m.setObjective(sum([Z[j, k] * (Beta_0[j] + sum(Beta_1[j, i] * XC[k, i] for i in range(d))) for j in range(J) for k in range(K)]), GRB.MINIMIZE)\n",
    "    \n",
    "    for j in range(J):\n",
    "        m.addConstr(Beta_0[j] + sum([Beta_1[j, i] * mu[i] for i in range(d)]) >= marginal_estimation[j])\n",
    "        \n",
    "    for j in range(J):\n",
    "        for n in range(len(Xs[j])):\n",
    "            m.addConstr(Delta[j, n] == Beta_0[j] + sum([Beta_1[j, i] * Xs[j][n, i] for i in range(d)]) - Rs[j][n])\n",
    "    \n",
    "    m.addConstr(sum([Delta[j, n] ** 2 for j in range(J) for n in range(len(Xs[j]))]) <= Gamma ** 2)\n",
    "    \n",
    "    for j in range(J):\n",
    "        m.addConstr(sum([(Beta_1[j, i] * X_std[i]) ** 2 for i in range(d)]) <= gamma[j] ** 2)\n",
    "        \n",
    "    m.optimize()\n",
    "    sol = m.getAttr('X', Beta_1)\n",
    "    print(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d829d9-9bb5-456c-b2de-a98bc14d5397",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def robust_opt_soc(X_new, Gamma, gamma):\n",
    "    m = Model()\n",
    "    m.setParam('LogToConsole', 0)\n",
    "    m.setParam('BarHomogeneous', 1)\n",
    "    m.setParam('Method', 2)\n",
    "    m.setParam('MIPGap', 0.01)\n",
    "    \n",
    "    Z = m.addVars(((j, k) for k in range(K) for j in range(J)), vtype=GRB.BINARY, lb=0, ub=1)\n",
    "    Lambda = m.addVars((0,), vtype=GRB.CONTINUOUS, lb=0)\n",
    "    Theta = m.addVars((j for j in range(J)), vtype=GRB.CONTINUOUS, lb=-GRB.INFINITY, ub=GRB.INFINITY)\n",
    "    Nu = m.addVars(((j, n) for j in range(J) for n in range(len(Xs[j]))), vtype=GRB.CONTINUOUS, lb=-GRB.INFINITY, ub=GRB.INFINITY)\n",
    "    _lambda = m.addVars((j for j in range(J)), vtype=GRB.CONTINUOUS, lb=0, ub=GRB.INFINITY)\n",
    "    alpha = m.addVars(((j, i) for j in range(J) for i in range(d)), vtype=GRB.CONTINUOUS, lb=-GRB.INFINITY, ub=GRB.INFINITY)\n",
    "    \n",
    "    marginal_gain = sum([Theta[j] * mean_estimation[j] for j in range(J)])\n",
    "    estimate_gain = sum([Rs[j][n] * Nu[j, n] for j in range(J) for n in range(len(Xs[j]))])\n",
    "    bias_loss = Gamma * Lambda[0]\n",
    "    local_loss = sum([gamma[j] * _lambda[j] for j in range(J)])\n",
    "    \n",
    "    m.setObjective(marginal_gain + estimate_gain - bias_loss - local_loss, GRB.MAXIMIZE)\n",
    "  \n",
    "    ## part 0\n",
    "    m.addConstr(sum(Theta[j] for j in range(J)) + sum([Nu[j, n] for j in range(J) for n in range(len(Xs[j]))]) == sum([Z[j, k] for j in range(J) for k in range(K)]))\n",
    "    for j in range(1, J):\n",
    "        m.addConstr(Theta[j] + sum([Nu[j, n] for n in range(len(Xs[j]))]) == sum([Z[j, k] for k in range(K)]))\n",
    "\n",
    "    ## part 1\n",
    "    for i in range(d):\n",
    "        m.addConstr(sum(Theta[j] * mu[i] for j in range(J)) + sum(Nu[j, n] * Xs[j][n, i] for j in range(J) for n in range(len(Xs[j]))) + sum(alpha[j, i] * sigma[i] for j in range(J)) == sum([Z[j, k] * X_new[k][i] for j in range(J) for k in range(K)]))\n",
    "        for j in range(1, J):\n",
    "            m.addConstr(Theta[j] * mu[i] + sum(Nu[j, n] * Xs[j][n, i] for n in range(len(Xs[j]))) + alpha[j, i] * sigma[i] == sum([Z[j, k] * X_new[k][i] for k in range(K)]))\n",
    "\n",
    "    ## part 2\n",
    "    m.addConstr(sum([Nu[j, n] ** 2 for j in range(J) for n in range(len(Xs[j]))]) <= Lambda[0] ** 2)\n",
    "    \n",
    "    for j in range(J):\n",
    "        m.addConstr(sum([alpha[j, i] ** 2 for i in range(d)]) <= _lambda[j] ** 2)\n",
    "        \n",
    "    m.addConstr(Lambda[0] <= 1000)   \n",
    "    for j in range(J):\n",
    "        m.addConstr(_lambda[j] <= 1000)   \n",
    "        \n",
    "    for k in range(K):\n",
    "        m.addConstr(sum([Z[j, k] for j in range(J)]) == 1)\n",
    "        \n",
    "#     m.addConstr(sum(Z[1, k] for k in range(K)) <= 0.3 * K)\n",
    "#     m.addConstr(sum(Z[2, k] for k in range(K)) <= 0.3 * K)\n",
    "        \n",
    "\n",
    "    m.addConstr(Lambda[0] == 0)\n",
    "\n",
    "    m.optimize()\n",
    "    \n",
    "    policy = ['NA'] * K\n",
    "    sol = m.getAttr('X', Z)\n",
    "    obj = m.objVal\n",
    "    for j, k in sol:\n",
    "        if sol[j, k] > 0.9:\n",
    "             policy[k] = j\n",
    "    \n",
    "    return policy, obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10918ef9-7668-4e01-9b3f-9afc6e847797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def det_opt(Phi):\n",
    "    m = Model()\n",
    "    m.setParam('LogToConsole', 0)\n",
    "    m.setParam('BarHomogeneous', 1)\n",
    "    m.setParam('Method', 2)\n",
    "    \n",
    "    Z = m.addVars(((j, k) for k in range(K) for j in range(J)), vtype=GRB.BINARY, lb=0, ub=1)\n",
    "  \n",
    "    m.setObjective(sum([Z[j, k] * Phi[j, k] for j in range(J) for k in range(K)]), GRB.MAXIMIZE)\n",
    "  \n",
    "    for k in range(K):\n",
    "        m.addConstr(sum([Z[j, k] for j in range(J)]) == 1)\n",
    "   \n",
    "    m.optimize()\n",
    "    \n",
    "    policy = ['NA'] * K\n",
    "    sol = m.getAttr('X', Z)\n",
    "    obj = m.objVal\n",
    "    for j, k in sol:\n",
    "        if sol[j, k] > 0.9:\n",
    "             policy[k] = j\n",
    "    \n",
    "    return policy, obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8643742a-1b48-429e-b66f-a6c575925217",
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 3\n",
    "d = 20\n",
    "p = [1 / J] * J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "1e887741-6970-4d0c-8468-b32e08c0f73f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate coefficients\n",
    "def generate_model():\n",
    "    np.random.seed(5)\n",
    "    beta_share_0 = np.random.normal(0.3, 0)\n",
    "    beta_share_1 = np.random.normal(0, 0.2, size=d)\n",
    "\n",
    "    beta_0 = np.random.normal(0, 0.1, size=J-1)\n",
    "    beta_1 = np.random.normal(0, 0.05, size=(J-1, d))\n",
    "    \n",
    "    return beta_share_0, beta_share_1, beta_0, beta_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c217fed0-ede3-4c23-b963-113ef208122a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate data\n",
    "def generate_samples(N, seed):\n",
    "    np.random.seed(seed)\n",
    "#     X_mean = np.random.uniform(0.2, 0.8, size=d)\n",
    "    \n",
    "    Xs = []\n",
    "    Rs = []\n",
    "    for j in range(J):\n",
    "#         X = np.random.binomial(n=1, p=X_mean, size=(int(p[j] * N), d))\n",
    "        X = np.random.normal(0, 1, size=(int(p[j] * N), d))\n",
    "        R = []\n",
    "        for X_n in X:\n",
    "            R_share = beta_share_0 + np.dot(X_n, beta_share_1)\n",
    "            R_noise = np.random.normal(0, 0.5)\n",
    "            if j == 0:\n",
    "                R_treat = 0\n",
    "            else:\n",
    "                R_treat = beta_0[j-1] + np.dot(X_n, beta_1[j-1]) \n",
    "\n",
    "            R_n = R_share + R_noise + R_treat    \n",
    "            R.append(R_n)\n",
    "\n",
    "        Xs.append(X)\n",
    "        Rs.append(R)\n",
    "        \n",
    "    Xv = []\n",
    "    Rv = []\n",
    "\n",
    "    for j in range(J):\n",
    "#         X = np.random.binomial(n=1, p=X_mean, size=(int(p[j] * N), d))\n",
    "        X = np.random.normal(0, 1, size=(int(p[j] * N), d))\n",
    "        R = []\n",
    "        for X_n in X:\n",
    "            R_share = beta_share_0 + np.dot(X_n, beta_share_1)\n",
    "            R_noise = np.random.normal(0, 0.5)\n",
    "            if j == 0:\n",
    "                R_treat = 0\n",
    "            else:\n",
    "                R_treat = beta_0[j-1] + np.dot(X_n, beta_1[j-1]) \n",
    "\n",
    "            R_n = R_share + R_noise + R_treat    \n",
    "            R.append(R_n)\n",
    "\n",
    "        Xv.append(X)\n",
    "        Rv.append(R)\n",
    "        \n",
    "    mu = np.mean(np.concatenate(Xs), 0)\n",
    "        \n",
    "    sigma = np.array([np.std(np.concatenate(Xs)[:,i]) for i in range(d)])\n",
    "    Sigma = np.cov(np.concatenate(Xs).T)\n",
    "    \n",
    "    return Xs, np.array(Rs), Xv, np.array(Rv), mu, sigma, Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c16cff5f-00c4-4b26-b191-00c9c430ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates():\n",
    "    np.random.seed(1000)\n",
    "    \n",
    "#     Xc = np.random.binomial(n=1, p=X_mean, size=(K, d))\n",
    "    Xc = np.random.normal(0, 1, size=(K, d))\n",
    "    Rc = []\n",
    "    for X_n in Xc:\n",
    "        Rc_n = []\n",
    "        R_share = beta_share_0 + np.dot(X_n, beta_share_1)\n",
    "        R_noise = np.random.normal(0, 0.5)\n",
    "        for j in range(J):\n",
    "            if j == 0:\n",
    "                R_treat = 0\n",
    "            else:\n",
    "                R_treat = beta_0[j-1] + np.dot(X_n, beta_1[j-1]) \n",
    "            R_n = R_share + R_noise + R_treat\n",
    "            Rc_n.append(R_n)\n",
    "        Rc.append(Rc_n)\n",
    "        \n",
    "    return Xc, Rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2bf37f46-58d2-41a7-95f8-e8acb4217baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## moment information\n",
    "def estimate_moments():\n",
    "    mean_estimation = []\n",
    "    for j in range(J):\n",
    "        if j == 0:\n",
    "            ave_effect = hat_beta_share_0 + np.dot(mu, hat_beta_share_1) \n",
    "        if j >= 1:\n",
    "            ave_effect = hat_beta_share_0 + hat_beta_0[j-1] + np.dot(mu, (hat_beta_share_1 + hat_beta_1[j-1])) \n",
    "        \n",
    "        mean_estimation.append(ave_effect)\n",
    "        \n",
    "    variance_estimation = []\n",
    "    for j in range(J):\n",
    "        var = 0\n",
    "        for i in range(d):\n",
    "            if j == 0:\n",
    "                tmp = hat_beta_share_1[i] * sigma[i]\n",
    "            if j >= 1:\n",
    "                tmp = (hat_beta_share_1[i] + hat_beta_1[j-1][i]) * sigma[i]\n",
    "            var += (tmp ** 2)\n",
    "        variance_estimation.append(np.sqrt(var))\n",
    "\n",
    "    variance_estimation = np.array(variance_estimation)\n",
    "    \n",
    "    return mean_estimation, variance_estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6227e543-0203-4e73-bb9b-1254731bf377",
   "metadata": {},
   "outputs": [],
   "source": [
    "## training\n",
    "def prediction(reg):\n",
    "    hat_beta_share_0, params, coefs_loss = linear_regress(Xs, Rs, reg)\n",
    "    hat_beta_0, hat_beta_1 = [], []\n",
    "    hat_beta_share_1 = params[:d]\n",
    "\n",
    "    for j in range(1, J):\n",
    "        hat_beta_0.append(params[d + (j-1) * (d+1)])\n",
    "        hat_beta_1.append(params[d + (j-1) * (d+1) + 1: d + j * (d+1)])\n",
    "\n",
    "#     hat_Rs = []\n",
    "#     for j in range(J):\n",
    "#         hat_R = []\n",
    "#         for n in range(len(Xs[j])):\n",
    "#             hat_R_n = hat_beta_share_0 + np.dot(Xs[j][n], hat_beta_share_1)   \n",
    "#             if j >= 1:\n",
    "#                 hat_R_n += (hat_beta_0[j-1] + np.dot(Xs[j][n], hat_beta_1[j-1]))\n",
    "#             hat_R.append(hat_R_n)\n",
    "#         hat_Rs.append(hat_R)\n",
    "\n",
    "#     loss = metrics.mean_squared_error(Rs, hat_Rs) \n",
    "\n",
    "    return hat_beta_share_0, hat_beta_share_1, hat_beta_0, hat_beta_1, coefs_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a045cf1f-d6ae-46ed-b294-150ad306a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing\n",
    "def prescription():\n",
    "    gamma = variance_estimation\n",
    "    Gamma = np.sqrt(loss * r)\n",
    "\n",
    "    stats = []\n",
    "    policy_dis = [collections.defaultdict(int), collections.defaultdict(int)]\n",
    "    for b in range(1):\n",
    "        Xc, Rc = generate_candidates()\n",
    "        \n",
    "        if r > 1:\n",
    "            policy_robust, obj = robust(Xc, Gamma, gamma)\n",
    "            if obj >= 3000:\n",
    "                print('error')\n",
    "        policy_lr, obj = greedy(Xc)\n",
    "        policy_optimal, obj = optimal(Xc)\n",
    "\n",
    "        rewards_robust, rewards_lr, rewards_opt = 0, 0, 0\n",
    "        for k in range(K):\n",
    "            if r > 1:\n",
    "                W_k = policy_robust[k]\n",
    "                policy_dis[0][W_k] += 1\n",
    "                rewards_robust += Rc[k][W_k]\n",
    "\n",
    "            W_k = policy_lr[k]\n",
    "            policy_dis[1][W_k] += 1\n",
    "            rewards_lr += Rc[k][W_k]\n",
    "            \n",
    "            W_k = policy_optimal[k]\n",
    "            rewards_opt += Rc[k][W_k]\n",
    "\n",
    "        stats.append([rewards_robust, rewards_lr, rewards_opt])\n",
    "        \n",
    "    return stats, policy_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1fbd9772-a259-4492-aeb9-9b5f7582e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# marginal_estimation = {}\n",
    "# for j in range(J):\n",
    "#     boot_strap = []\n",
    "#     for _ in range(1000):\n",
    "#         boot_strap.append(np.mean(np.random.choice(Rs[j], size=len(Rs[j]), replace=True)))\n",
    "#     ave_effect_lower = sorted(boot_strap)[100]\n",
    "#     marginal_estimation[j] = ave_effect_lower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7cc24d-a93f-47f0-8a60-146637928fa7",
   "metadata": {},
   "source": [
    "## Some Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "31f675c6-0f89-4992-8107-bca22dc70e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def greedy(Xc):\n",
    "    Phi = {}\n",
    "    for k in range(K):\n",
    "        for j in range(J):\n",
    "            Yc_pred = hat_beta_share_0 + np.dot(Xc[k], hat_beta_share_1)\n",
    "            if j >= 1:\n",
    "                Yc_pred += (hat_beta_0[j-1] + np.dot(Xc[k], hat_beta_1[j-1]))\n",
    "            Phi[j, k] = Yc_pred\n",
    "\n",
    "    policy_lr, obj = det_opt(Phi)\n",
    "                \n",
    "    return policy_lr, obj\n",
    "\n",
    "def optimal(Xc):      \n",
    "    Phi = {}\n",
    "    for k in range(K):\n",
    "        for j in range(J):\n",
    "            Yc_pred = beta_share_0 + np.dot(Xc[k], beta_share_1)\n",
    "            if j >= 1:\n",
    "                Yc_pred += (beta_0[j-1] + np.dot(Xc[k], beta_1[j-1]))\n",
    "            Phi[j, k] = Yc_pred\n",
    "\n",
    "    policy_opt, obj = det_opt(Phi)\n",
    "   \n",
    "    return policy_opt, obj\n",
    "\n",
    "\n",
    "def robust(Xc, Gamma, gamma):\n",
    "    #policy_robust, sol = robust_opt(Gamma)\n",
    "    policy_robust, obj = robust_opt_soc(Xc, Gamma, gamma)\n",
    "    \n",
    "    return policy_robust, obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5b22c3-ac51-445a-a2f3-afca83f431bc",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ac026d86-e9a4-4530-803a-bc255f3f4bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f5bb7886-403b-484f-9626-2f3318d2d16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation: new, Number of samples per treatment: 600, Seed: 0\n",
      "0\n",
      "0.1009685101820583\n",
      "[0.         1.9977598  2.01102591]\n",
      "Estimation: new, Number of samples per treatment: 600, Seed: 1\n",
      "0\n",
      "0.09789083785154967\n",
      "[0.         2.00467224 2.01102591]\n",
      "Estimation: new, Number of samples per treatment: 600, Seed: 2\n",
      "0\n",
      "0.08922091448607888\n",
      "[0.         2.00117622 2.01102591]\n",
      "Estimation: new, Number of samples per treatment: 600, Seed: 3\n",
      "0\n",
      "0.09130191924485316\n",
      "[0.         2.00473482 2.01102591]\n",
      "Estimation: new, Number of samples per treatment: 600, Seed: 4\n",
      "0\n",
      "0.09403793444910213\n",
      "[0.         2.00409144 2.01102591]\n"
     ]
    }
   ],
   "source": [
    "beta_share_0, beta_share_1, beta_0, beta_1 = generate_model()\n",
    "\n",
    "output = {}\n",
    "for N in [600]:\n",
    "    for reg in ['new']:\n",
    "        performance, predict_loss = [], []\n",
    "        for seed in range(5):\n",
    "            print('Estimation: ' + str(reg) + ', Number of samples per treatment: ' + str(N) + ', Seed: ' + str(seed))\n",
    "            Xs, Rs, Xv, Rv, mu, sigma, Sigma = generate_samples(N, seed)\n",
    "            hat_beta_share_0, hat_beta_share_1, hat_beta_0, hat_beta_1, coefs_loss = prediction(reg)\n",
    "            mean_estimation, variance_estimation = estimate_moments()\n",
    "            \n",
    "            if reg == 'ordinal':\n",
    "                r = 1\n",
    "            else:\n",
    "                r = 1\n",
    "            stats, policy_dis = prescription()\n",
    "            \n",
    "            res = np.mean(stats, axis=0) / K\n",
    "            print(res)\n",
    "            performance.append([res[0], res[1], max(res[0], res[1])])\n",
    "            predict_loss.append(coefs_loss)\n",
    "\n",
    "        output[N, reg] = performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2fc1a150-c907-4a79-9a6c-214af355731c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.   , 0.358, 0.358])]\n",
      "[array([0.   , 0.015, 0.015])]\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "for reg in ['ordinal']:\n",
    "    ave, std = [], []\n",
    "    for N in [300]:\n",
    "        ave.append(np.round(np.mean(output[N, reg], axis=0), 3))\n",
    "        std.append(np.round(np.std(output[N, reg], axis=0), 3))\n",
    "    \n",
    "    print(ave)\n",
    "    print(std)\n",
    "    print('---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b2fdf6a7-fec1-419a-b40d-1712f42faf3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12585374842795244"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predict_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0fc2412b-4d9f-42e4-8b34-ee67b9b096f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[defaultdict(int, {}), defaultdict(int, {1: 392, 2: 198, 0: 410})]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "108849cb-71e8-47dd-8ef2-a886d14faf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6e92346668>]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0, 0.02, 0.04, 0.06, 0.08, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.6, 0.7, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2, 10, 20]\n",
    "y = predict_loss[0]\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "dbca8062-54f4-48a9-851e-cccf8cb048fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.29780531, 1.21832063, 1.08291991])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(Rs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7aef2571-3ce8-4f79-9b04-69c9a0591a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.06315716, -0.00061949]),\n",
       " array([[-0.00505338, -0.00261541,  0.01246088,  0.009883  ,  0.06674243,\n",
       "         -0.00434378,  0.07807661, -0.01529265, -0.02388657,  0.00503691,\n",
       "          0.01777192,  0.01348062,  0.06459817,  0.05696715,  0.02472202,\n",
       "         -0.01681681, -0.00503072,  0.0706699 ,  0.01106271, -0.06553866,\n",
       "         -0.03447826, -0.02887566,  0.05761024, -0.0053582 ,  0.11300534,\n",
       "          0.03283097,  0.00624034, -0.0217852 ,  0.04860897, -0.01203556],\n",
       "        [-0.04120617,  0.02840664,  0.00063792,  0.05945304, -0.00367967,\n",
       "         -0.1429844 ,  0.03946832, -0.09388704,  0.07693781,  0.09106824,\n",
       "         -0.02135157, -0.0582351 , -0.0698537 ,  0.04363273, -0.01010591,\n",
       "         -0.029918  , -0.01217099,  0.10442573,  0.01734597,  0.03728635,\n",
       "          0.03884538,  0.05092106,  0.05306757, -0.03552332, -0.01075939,\n",
       "         -0.03803802, -0.03555816,  0.05707539, -0.02508778, -0.00395757]]))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_0, beta_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1ab0603f-8a65-4098-a2d4-601682344836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3,\n",
       " array([-0.06617403,  0.48615424, -0.05041843,  0.02192197,  0.31649622,\n",
       "        -0.18184648, -0.11832733,  0.03752065, -0.06597399, -0.23855292,\n",
       "        -0.0409753 , -0.07176579,  0.12069432, -0.33295771, -0.14003581,\n",
       "         0.2302782 ,  0.3714662 , -0.30223591,  0.1289695 , -0.19612158,\n",
       "        -0.17137063, -0.17437584, -0.08450159,  0.19928797,  0.14248425,\n",
       "         0.01182885, -0.07266218,  0.00065777, -0.02118609,  0.15861066]))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_share_0, beta_share_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "60e775dd-c8a4-4d54-8d0f-133d28b81fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052170986060615335"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(beta_1[0] ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ebfbd6b0-e559-4860-a130-d1c60c6cabc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2348482343696064"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(np.dot(Xs[1], beta_1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d8bce23f-16da-4989-b9e4-fd50b385d329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0268992462603563"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(np.dot(Xs[0], beta_share_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dccf5f1-190f-431e-b744-721640e10c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
