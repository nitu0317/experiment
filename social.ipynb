{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988ffc60-23ba-47b8-a890-ddaaa0020c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from gurobipy import *\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import collections\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b693754-34c2-4b21-92c8-08dcfed2e123",
   "metadata": {},
   "source": [
    "## Estimation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "793fdcd8-e11d-4166-8ee3-817776c11d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## linear regression\n",
    "def linear_regress(Xs, Rs, reg):\n",
    "    X_train, R_train = [], []\n",
    "    for j in range(J):\n",
    "        tmp = np.concatenate((Xs[j], np.zeros((len(Xs[j]), (d+1) * (J-1)))), axis=1)\n",
    "        if j >= 1:\n",
    "            for n in range(len(Rs[j])):\n",
    "                tmp[n][d + (j-1) * (d+1)] = 1\n",
    "                tmp[n][d + (j-1) * (d+1) + 1: d + j * (d+1)] = Xs[j][n]\n",
    "        \n",
    "        X_train.append(tmp)\n",
    "        R_train.append(Rs[j])\n",
    "    \n",
    "    X_trains = np.concatenate(X_train)\n",
    "    R_trains = np.concatenate(R_train)\n",
    "    \n",
    "    if reg == 'ordinal':\n",
    "        lr, cv_loss = ols(X_train, R_train)\n",
    "        return lr.intercept_, lr.coef_, cv_loss\n",
    "    elif reg == 'ridge':\n",
    "        m = linear_model.RidgeCV(cv=10)\n",
    "        lr = m.fit(X_trains, R_trains)\n",
    "    elif reg == 'lasso':\n",
    "        m = linear_model.LassoCV(cv=10)\n",
    "        lr = m.fit(X_trains, R_trains)  \n",
    "    elif reg == 'new':\n",
    "        res, cv_loss = new(X_train, R_train)\n",
    "        \n",
    "        return res[0], res[1:], cv_loss\n",
    "        \n",
    "    return lr.intercept_, lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8b34322f-7d17-4684-a6a9-c3c51b4fe643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new(X_train, R_train): \n",
    "    F = 10\n",
    "    p = (0, 0.5, 0.5)\n",
    "    \n",
    "    X_train_0 = np.concatenate((np.reshape(np.ones(len(X_train[0])), (-1, 1)), X_train[0]), axis=1)\n",
    "    X_train_1 = np.concatenate((np.reshape(np.ones(len(X_train[1])), (-1, 1)), X_train[1]), axis=1)\n",
    "    X_train_2 = np.concatenate((np.reshape(np.ones(len(X_train[2])), (-1, 1)), X_train[2]), axis=1)\n",
    "    \n",
    "    X_fold = {0: np.split(X_train_0, 10), 1: np.split(X_train_1, 10), 2: np.split(X_train_2, 10)}\n",
    "    R_fold = {0: np.split(R_train[0], 10), 1: np.split(R_train[1], 10), 2: np.split(R_train[2], 10)}\n",
    "    \n",
    "#     coefs = [0, 0.02, 0.04, 0.06, 0.08, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.6, 0.7, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2]\n",
    "    coefs = [0, 0.5, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 30]\n",
    "    coefs_loss = []\n",
    "    for coef in coefs:  \n",
    "        Loss = 0\n",
    "        for k in range(F):\n",
    "            R_valid = np.concatenate([R_fold[j][k] for j in range(J)])\n",
    "            X_valid = np.concatenate([X_fold[j][k] for j in range(J)])\n",
    "\n",
    "            R_input = np.concatenate([R_fold[j][l] for j in range(J) for l in range(F) if l != k])\n",
    "            X_input = np.concatenate([X_fold[j][l] for j in range(J) for l in range(F) if l != k])\n",
    "\n",
    "            beta = solve_convex(X_input, R_input, coef, p)\n",
    "\n",
    "            loss = np.sum((np.dot(X_valid, beta) - R_valid) ** 2)\n",
    "            Loss += loss\n",
    "        coefs_loss.append(Loss/(J * N))\n",
    "    \n",
    "    cv_coef = coefs[np.argmin(coefs_loss)]\n",
    "    cv_loss = np.min(coefs_loss) \n",
    "    print(cv_coef)\n",
    "    print(coefs_loss)\n",
    "    beta = solve_convex(np.concatenate([X_train_0, X_train_1, X_train_2]), np.concatenate(R_train), cv_coef, p)\n",
    "\n",
    "    return beta, coefs_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7fffc4d2-fb18-4d94-b5ca-5d67b959c8cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ols(X_train, R_train): \n",
    "    F = 10\n",
    "    X_fold = {0: np.split(X_train[0], F), 1: np.split(X_train[1], F), 2: np.split(X_train[2], F)}\n",
    "    R_fold = {0: np.split(R_train[0], F), 1: np.split(R_train[1], F), 2: np.split(R_train[2], F)}\n",
    "\n",
    "    Loss = 0\n",
    "    for k in range(F):\n",
    "        R_valid = np.concatenate([R_fold[j][k] for j in range(J)])\n",
    "        X_valid = np.concatenate([X_fold[j][k] for j in range(J)])\n",
    "\n",
    "        R_input = np.concatenate([R_fold[j][l] for j in range(J) for l in range(F) if l != k])\n",
    "        X_input = np.concatenate([X_fold[j][l] for j in range(J) for l in range(F) if l != k])\n",
    "\n",
    "        lr = linear_model.LinearRegression().fit(X_input, R_input) \n",
    "        loss = np.sum((lr.intercept_ + np.dot(X_valid, lr.coef_) - R_valid) ** 2)\n",
    "        Loss += loss\n",
    "    \n",
    "    m = linear_model.LinearRegression()\n",
    "    lr = m.fit(np.concatenate(X_train), np.concatenate(R_train))\n",
    "    cv_loss = Loss / (J * N)\n",
    "    print(cv_loss)\n",
    "    return lr, cv_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d2570af6-2f3e-429c-a9d2-9fe2ee44ba90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def solve_convex(X_input, R_input, _lambda, _prob):\n",
    "    beta = cp.Variable((d + 1) * J)\n",
    "    loss = cp.sum_squares(X_input @ beta - R_input) / len(R_input)\n",
    "    \n",
    "    regularizer = 0\n",
    "    for j in range(J):\n",
    "#         if j >= 1:\n",
    "#             for i in range(d):\n",
    "#                 regularizer += (sigma[i] * (beta[i+1+j*(d+1)])) ** 2 * _prob[j]        \n",
    "        \n",
    "        if j >= 1:\n",
    "            regularizer += cp.quad_form(beta[1+j*(d+1):(j+1)*(d+1)], Sigma) * _prob[j]    \n",
    "    \n",
    "#         if j == 0:\n",
    "#             for i in range(d):\n",
    "#                 regularizer += (sigma[i] * beta[i+1]) ** 2 * _prob[j]\n",
    "#         elif j >= 1:\n",
    "#             for i in range(d):\n",
    "#                 regularizer += (sigma[i] * (beta[i+1] + beta[i+1+j*(d+1)])) ** 2 * _prob[j]\n",
    "        \n",
    "#         if j == 0:\n",
    "#             regularizer += cp.quad_form(beta[1:d+1], Sigma) * _prob[j]\n",
    "#         else:\n",
    "#             regularizer += cp.quad_form(beta[1:d+1] + beta[1+j*(d+1):(j+1)*(d+1)], Sigma) * _prob[j]\n",
    "           \n",
    "                \n",
    "    prob = cp.Problem(cp.Minimize(loss + regularizer * _lambda))\n",
    "    prob.solve()\n",
    "    \n",
    "    return beta.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41850f31-6903-4a1e-bb98-a712b263861e",
   "metadata": {},
   "source": [
    "## Optimization Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86067260-2bf1-4438-a06e-103f80a27efa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inner_opt_soc(Z, Gamma, gamma):\n",
    "    m = Model()\n",
    "    m.setParam('LogToConsole', 0)\n",
    "    \n",
    "    Beta_0 = m.addVars((j for j in range(J)), vtype=GRB.CONTINUOUS, lb=-GRB.INFINITY, ub=GRB.INFINITY)\n",
    "    Beta_1 = m.addVars(((j, i) for j in range(J) for i in range(d)), vtype=GRB.CONTINUOUS, lb=-GRB.INFINITY, ub=GRB.INFINITY)\n",
    "    Delta = m.addVars(((j, n) for j in range(J) for n in range(len(Xs[j]))), vtype=GRB.CONTINUOUS, lb=-GRB.INFINITY, ub=GRB.INFINITY)\n",
    "    \n",
    "    m.setObjective(sum([Z[j, k] * (Beta_0[j] + sum(Beta_1[j, i] * XC[k, i] for i in range(d))) for j in range(J) for k in range(K)]), GRB.MINIMIZE)\n",
    "    \n",
    "    for j in range(J):\n",
    "        m.addConstr(Beta_0[j] + sum([Beta_1[j, i] * mu[i] for i in range(d)]) >= marginal_estimation[j])\n",
    "        \n",
    "    for j in range(J):\n",
    "        for n in range(len(Xs[j])):\n",
    "            m.addConstr(Delta[j, n] == Beta_0[j] + sum([Beta_1[j, i] * Xs[j][n, i] for i in range(d)]) - Rs[j][n])\n",
    "    \n",
    "    m.addConstr(sum([Delta[j, n] ** 2 for j in range(J) for n in range(len(Xs[j]))]) <= Gamma ** 2)\n",
    "    \n",
    "    for j in range(J):\n",
    "        m.addConstr(sum([(Beta_1[j, i] * X_std[i]) ** 2 for i in range(d)]) <= gamma[j] ** 2)\n",
    "        \n",
    "    m.optimize()\n",
    "    sol = m.getAttr('X', Beta_1)\n",
    "    print(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84d829d9-9bb5-456c-b2de-a98bc14d5397",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def robust_opt_soc(X_new, Gamma, gamma):\n",
    "    m = Model()\n",
    "    m.setParam('LogToConsole', 0)\n",
    "    m.setParam('BarHomogeneous', 1)\n",
    "    m.setParam('Method', 2)\n",
    "    m.setParam('MIPGap', 0.01)\n",
    "    \n",
    "    Z = m.addVars(((j, k) for k in range(K) for j in range(J)), vtype=GRB.BINARY, lb=0, ub=1)\n",
    "    Lambda = m.addVars((0,), vtype=GRB.CONTINUOUS, lb=0)\n",
    "    Theta = m.addVars((j for j in range(J)), vtype=GRB.CONTINUOUS, lb=-GRB.INFINITY, ub=GRB.INFINITY)\n",
    "    Nu = m.addVars(((j, n) for j in range(J) for n in range(len(Xs[j]))), vtype=GRB.CONTINUOUS, lb=-GRB.INFINITY, ub=GRB.INFINITY)\n",
    "    _lambda = m.addVars((j for j in range(J)), vtype=GRB.CONTINUOUS, lb=0, ub=GRB.INFINITY)\n",
    "    alpha = m.addVars(((j, i) for j in range(J) for i in range(d)), vtype=GRB.CONTINUOUS, lb=-GRB.INFINITY, ub=GRB.INFINITY)\n",
    "    \n",
    "    marginal_gain = sum([Theta[j] * mean_estimation[j] for j in range(J)])\n",
    "    estimate_gain = sum([Rs[j][n] * Nu[j, n] for j in range(J) for n in range(len(Xs[j]))])\n",
    "    bias_loss = Gamma * Lambda[0]\n",
    "    local_loss = sum([gamma[j] * _lambda[j] for j in range(J)])\n",
    "    \n",
    "    m.setObjective(marginal_gain + estimate_gain - bias_loss - local_loss, GRB.MAXIMIZE)\n",
    "  \n",
    "    ## part 0\n",
    "    m.addConstr(sum(Theta[j] for j in range(J)) + sum([Nu[j, n] for j in range(J) for n in range(len(Xs[j]))]) == sum([Z[j, k] for j in range(J) for k in range(K)]))\n",
    "    for j in range(1, J):\n",
    "        m.addConstr(Theta[j] + sum([Nu[j, n] for n in range(len(Xs[j]))]) == sum([Z[j, k] for k in range(K)]))\n",
    "\n",
    "    ## part 1\n",
    "    for i in range(d):\n",
    "        m.addConstr(sum(Theta[j] * mu[i] for j in range(J)) + sum(Nu[j, n] * Xs[j][n, i] for j in range(J) for n in range(len(Xs[j]))) + sum(alpha[j, i] * sigma[i] for j in range(J)) == sum([Z[j, k] * X_new[k][i] for j in range(J) for k in range(K)]))\n",
    "        for j in range(1, J):\n",
    "            m.addConstr(Theta[j] * mu[i] + sum(Nu[j, n] * Xs[j][n, i] for n in range(len(Xs[j]))) + alpha[j, i] * sigma[i] == sum([Z[j, k] * X_new[k][i] for k in range(K)]))\n",
    "\n",
    "    ## part 2\n",
    "    m.addConstr(sum([Nu[j, n] ** 2 for j in range(J) for n in range(len(Xs[j]))]) <= Lambda[0] ** 2)\n",
    "    \n",
    "    for j in range(J):\n",
    "        m.addConstr(sum([alpha[j, i] ** 2 for i in range(d)]) <= _lambda[j] ** 2)\n",
    "        \n",
    "    m.addConstr(Lambda[0] <= 1000)   \n",
    "    for j in range(J):\n",
    "        m.addConstr(_lambda[j] <= 1000)   \n",
    "        \n",
    "    for k in range(K):\n",
    "        m.addConstr(sum([Z[j, k] for j in range(J)]) == 1)\n",
    "        \n",
    "#     m.addConstr(sum(Z[1, k] for k in range(K)) <= 0.3 * K)\n",
    "#     m.addConstr(sum(Z[2, k] for k in range(K)) <= 0.3 * K)\n",
    "        \n",
    "\n",
    "    m.addConstr(Lambda[0] == 0)\n",
    "\n",
    "    m.optimize()\n",
    "    \n",
    "    policy = ['NA'] * K\n",
    "    sol = m.getAttr('X', Z)\n",
    "    obj = m.objVal\n",
    "    for j, k in sol:\n",
    "        if sol[j, k] > 0.9:\n",
    "             policy[k] = j\n",
    "    \n",
    "    return policy, obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10918ef9-7668-4e01-9b3f-9afc6e847797",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def det_opt(Phi):\n",
    "    m = Model()\n",
    "    m.setParam('LogToConsole', 0)\n",
    "    m.setParam('BarHomogeneous', 1)\n",
    "    m.setParam('Method', 2)\n",
    "    \n",
    "    Z = m.addVars(((j, k) for k in range(K) for j in range(J)), vtype=GRB.BINARY, lb=0, ub=1)\n",
    "  \n",
    "    m.setObjective(sum([Z[j, k] * Phi[j, k] for j in range(J) for k in range(K)]), GRB.MAXIMIZE)\n",
    "  \n",
    "    for k in range(K):\n",
    "        m.addConstr(sum([Z[j, k] for j in range(J)]) == 1)\n",
    "        \n",
    "#     m.addConstr(sum(Z[1, k] for k in range(K)) <= 0.3 * K)\n",
    "#     m.addConstr(sum(Z[2, k] for k in range(K)) <= 0.3 * K)\n",
    "   \n",
    "    m.optimize()\n",
    "    \n",
    "    policy = ['NA'] * K\n",
    "    sol = m.getAttr('X', Z)\n",
    "    obj = m.objVal\n",
    "    for j, k in sol:\n",
    "        if sol[j, k] > 0.99:\n",
    "             policy[k] = j\n",
    "    \n",
    "    return policy, obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1930060-448f-4024-8c05-8ae318cc7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw_neigh = pd.read_csv('../Data/Social/ProcessedData/socialpresswgeooneperhh_NEIGH.csv')\n",
    "data_raw_self = pd.read_csv('../Data/Social/ProcessedData/socialpresswgeooneperhh_SELF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0d3e944-4dba-424b-9686-4591f86b73cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0def8b0-2cb5-40af-be6e-5153f40c7150",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.concat((data_raw_neigh, data_raw_self.loc[data_raw_self['treat_self'] == 1]))\n",
    "data_raw = data_raw.rename(columns={'outcome_voted': 'Y', \"treat_neighbors\" : 'W1', \"treat_self\": 'W2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24737d2c-39d1-45b8-bc74-addc34899a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cts_variables_names = [\"yob\", \"hh_size\", \"totalpopulation_estimate\",\n",
    "                      \"percent_male\", \"median_age\", \"percent_62yearsandover\",\n",
    "                      \"percent_white\", \"percent_black\", \"percent_asian\", \"median_income\",\n",
    "                      \"employ_20to64\", \"highschool\", \"bach_orhigher\",\"percent_hispanicorlatino\"]\n",
    "\n",
    "binary_variables_names = [\"sex\", \"g2000\", \"g2002\", \"p2000\", \"p2002\", \"p2004\"]\n",
    "\n",
    "causal_names = [\"Y\", \"W1\", \"W2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed41b789-73a4-4467-9c4f-5211f4e94a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = data_raw.dropna()\n",
    "data_new = data_raw[cts_variables_names + binary_variables_names + causal_names] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c3ce886-8709-4332-90a4-6b652f9fc21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cts_variables_mean = data_raw[cts_variables_names].mean()\n",
    "# cts_variables_std = data_raw[cts_variables_names].std()\n",
    "# data_new = (data_raw[cts_variables_names] - cts_variables_mean) / cts_variables_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fb44ab2-e7be-4140-9b7a-fa4a1445bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_pool_0 = data_new.loc[(data_new['W1'] == 0) & (data_new['W2'] == 0)][:10000]\n",
    "data_train_pool_1 = data_new.loc[data_new['W1'] == 1][:10000]\n",
    "data_train_pool_2 = data_new.loc[data_new['W2'] == 1][:10000]\n",
    "\n",
    "data_test_0 = data_new.loc[(data_new['W1'] == 0) & (data_new['W2'] == 0)][10000:20000]\n",
    "data_test_1 = data_new.loc[data_new['W1'] == 1][10000:20000]\n",
    "data_test_2 = data_new.loc[data_new['W2'] == 1][10000:20000]\n",
    "data_test = pd.concat((data_test_0, data_test_1, data_test_2))\n",
    "# data_test = pd.concat((data_test_0, data_test_1))\n",
    "\n",
    "cts_variables_mean = data_test[cts_variables_names].mean()\n",
    "cts_variables_std = data_test[cts_variables_names].std()\n",
    "data_test[cts_variables_names] = (data_test[cts_variables_names] - cts_variables_mean) / cts_variables_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe1fde73-b485-4796-ba90-e74e64a8dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(N, seed):\n",
    "    np.random.seed(seed)\n",
    "    data_train_0 = data_train_pool_0.sample(n=N)\n",
    "    data_train_1 = data_train_pool_1.sample(n=N)\n",
    "    data_train_2 = data_train_pool_2.sample(n=N)\n",
    "    data_train = pd.concat((data_train_0, data_train_1, data_train_2))\n",
    "#     data_train = pd.concat((data_train_0, data_train_1))\n",
    "    \n",
    "    cts_variables_mean = data_train[cts_variables_names].mean()\n",
    "    cts_variables_std = data_train[cts_variables_names].std()\n",
    "    data_train[cts_variables_names] = (data_train[cts_variables_names] - cts_variables_mean) / cts_variables_std\n",
    "    \n",
    "    Xs = []\n",
    "    Rs = []\n",
    "    for j in range(J):\n",
    "        if j == 0:\n",
    "            data_train_0[cts_variables_names] = (data_train_0[cts_variables_names] - cts_variables_mean) / cts_variables_std\n",
    "            X = data_train_0[cts_variables_names + binary_variables_names].to_numpy()\n",
    "            Xs.append(X)\n",
    "            Y = data_train_0['Y'].to_numpy()\n",
    "            Rs.append(Y)\n",
    "        if j == 1:\n",
    "            data_train_1[cts_variables_names] = (data_train_1[cts_variables_names] - cts_variables_mean) / cts_variables_std\n",
    "            X = data_train_1[cts_variables_names + binary_variables_names].to_numpy()\n",
    "            Xs.append(X)\n",
    "            Y = data_train_1['Y'].to_numpy()\n",
    "            Rs.append(Y)\n",
    "        if j == 2:\n",
    "            data_train_2[cts_variables_names] = (data_train_2[cts_variables_names] - cts_variables_mean) / cts_variables_std\n",
    "            X = data_train_2[cts_variables_names + binary_variables_names].to_numpy()\n",
    "            Xs.append(X)\n",
    "            Y = data_train_2['Y'].to_numpy()\n",
    "            Rs.append(Y)\n",
    "            \n",
    "    mu = data_train[cts_variables_names + binary_variables_names].mean().to_numpy()\n",
    "    sigma = data_train[cts_variables_names + binary_variables_names].std().to_numpy()\n",
    "    Sigma = data_train[cts_variables_names + binary_variables_names].cov().to_numpy()\n",
    "    \n",
    "    propensity = [len(data_test_0)/len(data_test), len(data_test_1)/len(data_test), len(data_test_2)/len(data_test)]\n",
    "    \n",
    "    return Xs, Rs, mu, sigma, Sigma, propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bf37f46-58d2-41a7-95f8-e8acb4217baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## moment information\n",
    "def estimate_moments():\n",
    "    mean_estimation = []\n",
    "    for j in range(J):\n",
    "        if j == 0:\n",
    "            ave_effect = hat_beta_share_0 + np.dot(mu, hat_beta_share_1) \n",
    "        if j >= 1:\n",
    "            ave_effect = hat_beta_share_0 + hat_beta_0[j-1] + np.dot(mu, (hat_beta_share_1 + hat_beta_1[j-1])) \n",
    "\n",
    "#         ave_effect = np.mean(Rs[j])\n",
    "        \n",
    "        mean_estimation.append(ave_effect)\n",
    "        \n",
    "    std_estimation = []\n",
    "    for j in range(J):\n",
    "        var = 0\n",
    "        for i in range(d):\n",
    "#             if j == 0:\n",
    "#                 tmp = hat_beta_share_1[i] * sigma[i]\n",
    "#             if j >= 1:\n",
    "#                 tmp = (hat_beta_share_1[i] + hat_beta_1[j-1][i]) * sigma[i]\n",
    "#             var += (tmp ** 2)\n",
    "            if j == 0:\n",
    "                tmp = hat_beta_share_1\n",
    "                var = np.dot(np.dot(tmp.T, Sigma), tmp)\n",
    "            else:\n",
    "                tmp = hat_beta_share_1 + hat_beta_1[j-1]\n",
    "                var = np.dot(np.dot(tmp.T, Sigma), tmp)\n",
    "            \n",
    "        std_estimation.append(np.sqrt(var))\n",
    "\n",
    "    std_estimation = np.array(std_estimation)\n",
    "    \n",
    "    return mean_estimation, std_estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6227e543-0203-4e73-bb9b-1254731bf377",
   "metadata": {},
   "outputs": [],
   "source": [
    "## training\n",
    "def prediction(method):\n",
    "    hat_beta_share_0, params, coefs_loss = linear_regress(Xs, Rs, method)\n",
    "\n",
    "    hat_beta_0, hat_beta_1 = [], []\n",
    "    hat_beta_share_1 = params[:d]\n",
    "\n",
    "    for j in range(1, J):\n",
    "        hat_beta_0.append(params[d + (j-1) * (d+1)])\n",
    "        hat_beta_1.append(params[d + (j-1) * (d+1) + 1: d + j * (d+1)])\n",
    "\n",
    "#     hat_Rs = []\n",
    "#     for j in range(J):\n",
    "#         hat_R = []\n",
    "#         for n in range(len(Xs[j])):\n",
    "#             hat_R_n = hat_beta_share_0 + np.dot(Xs[j][n], hat_beta_share_1)   \n",
    "#             if j >= 1:\n",
    "#                 hat_R_n += (hat_beta_0[j-1] + np.dot(Xs[j][n], hat_beta_1[j-1]))\n",
    "#             hat_R.append(hat_R_n)\n",
    "#         hat_Rs.append(hat_R)\n",
    "#     hat_Rs = np.array(hat_Rs)\n",
    "    \n",
    "#     loss = 0\n",
    "#     for j in range(J):\n",
    "#         loss += np.sum((Rs[j] - hat_Rs[j]) ** 2)\n",
    "    \n",
    "    return hat_beta_share_0, hat_beta_share_1, hat_beta_0, hat_beta_1, coefs_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a045cf1f-d6ae-46ed-b294-150ad306a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing\n",
    "def prescription():\n",
    "    gamma = variance_estimation\n",
    "    Gamma = np.sqrt(loss * r)\n",
    "\n",
    "    stats = []\n",
    "    policy_dis = [collections.defaultdict(int), collections.defaultdict(int)]\n",
    "    np.random.seed(1)\n",
    "    for b in range(int(len(data_test) / K)):\n",
    "        Xc, Rc, Wc = [], [], []\n",
    "        for i in range(b * K, (b + 1) * K):\n",
    "            row = data_test.iloc[i]\n",
    "            Xc.append(row[cts_variables_names + binary_variables_names])\n",
    "            Rc.append(row['Y'])\n",
    "            if row['W1'] == 1:\n",
    "                Wc.append(1)\n",
    "            elif row['W2'] == 1:\n",
    "                Wc.append(2)\n",
    "            else:\n",
    "                Wc.append(0)\n",
    "\n",
    "        if r > 1:\n",
    "            policy_robust, obj = robust(Xc, Gamma, gamma)\n",
    "            if obj >= 3000:\n",
    "                print('error')\n",
    "        policy_lr, obj = greedy(Xc)\n",
    "\n",
    "        rewards_robust, rewards_lr = 0, 0\n",
    "        for k in range(K):\n",
    "            if r > 1:\n",
    "                W_k = policy_robust[k]\n",
    "                policy_dis[0][W_k] += 1\n",
    "                if W_k == Wc[k]:\n",
    "                    rewards_robust += (Rc[k] / propensity[int(Wc[k])])\n",
    "\n",
    "            W_k = policy_lr[k]\n",
    "            policy_dis[1][W_k] += 1\n",
    "            if W_k == Wc[k]:\n",
    "                rewards_lr += (Rc[k] / propensity[int(Wc[k])])\n",
    "\n",
    "        stats.append([rewards_robust, rewards_lr])\n",
    "        \n",
    "    return stats, policy_dis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7cc24d-a93f-47f0-8a60-146637928fa7",
   "metadata": {},
   "source": [
    "## Some Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31f675c6-0f89-4992-8107-bca22dc70e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def greedy(Xc):\n",
    "    Phi = {}\n",
    "    for k in range(K):\n",
    "        for j in range(J):\n",
    "            Yc_pred = hat_beta_share_0 + np.dot(Xc[k], hat_beta_share_1)\n",
    "            if j >= 1:\n",
    "                Yc_pred += (hat_beta_0[j-1] + np.dot(Xc[k], hat_beta_1[j-1]))\n",
    "            Phi[j, k] = Yc_pred\n",
    "\n",
    "    policy_lr, obj = det_opt(Phi)\n",
    "                \n",
    "    return policy_lr, obj\n",
    "\n",
    "def optimal(Xc):      \n",
    "    Phi = {}\n",
    "    for k in range(K):\n",
    "        for j in range(J):\n",
    "            Yc_pred = beta_share_0 + np.dot(Xc[k], beta_share_1)\n",
    "            if j >= 1:\n",
    "                Yc_pred += (beta_0[j-1] + np.dot(Xc[k], beta_1[j-1]))\n",
    "            Phi[j, k] = Yc_pred\n",
    "\n",
    "    policy_opt, obj = det_opt(Phi)\n",
    "   \n",
    "    return policy_opt   \n",
    "\n",
    "def robust(Xc, Gamma, gamma):\n",
    "    #policy_robust, sol = robust_opt(Gamma)\n",
    "    policy_robust, obj = robust_opt_soc(Xc, Gamma, gamma)\n",
    "    \n",
    "    return policy_robust, obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5b22c3-ac51-445a-a2f3-afca83f431bc",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5c11db1-9867-4864-95e2-946af63fe6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 1000\n",
    "d = len(cts_variables_names) + len(binary_variables_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "629d9329-ad82-4f8c-82ec-200d545354ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation: ordinal, Number of samples per treatment: 400, Seed: 0\n",
      "0.22306245258500193\n",
      "[0.     0.3286]\n"
     ]
    }
   ],
   "source": [
    "output = {}\n",
    "\n",
    "for N in [400]:\n",
    "    for reg in ['ordinal']:\n",
    "        performance, predict_loss = [], []\n",
    "        for seed in range(1):\n",
    "            print('Estimation: ' + str(reg) + ', Number of samples per treatment: ' + str(N) + ', Seed: ' + str(seed))\n",
    "            Xs, Rs, mu, sigma, Sigma, propensity = generate_samples(N, seed)\n",
    "            hat_beta_share_0, hat_beta_share_1, hat_beta_0, hat_beta_1, coefs_loss = prediction(reg)\n",
    "            mean_estimation, variance_estimation = estimate_moments()\n",
    "#             print(mean_estimation)\n",
    "#             print(variance_estimation)\n",
    "#             print(hat_beta_1)\n",
    "            \n",
    "            if reg == 'ordinal':\n",
    "                r = 1\n",
    "            else:\n",
    "                r = 1\n",
    "            stats, policy_dis = prescription()\n",
    "            \n",
    "            res = np.mean(stats, axis=0) / K\n",
    "            print(res)\n",
    "            performance.append([res[0], res[1], max(res[0], res[1])])\n",
    "            predict_loss.append(coefs_loss)\n",
    "\n",
    "        output[N, reg] = performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2642e7d9-fe97-40a0-88d0-799e21045049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16914545, -0.44469787,  0.12785938, -0.01526492,  0.00999671,\n",
       "        0.17633822,  0.07029145, -0.07152893,  0.05589052,  0.02201346])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(Xs[1], hat_beta_1[0])[:10] + hat_beta_0[0] - (np.dot(Xs[1], hat_beta_1[1])[:10] + hat_beta_0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8346529a-0756-4992-be25-f0f2984ec831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05356523,  0.67286614, -0.06504211,  0.37791125, -0.09256835,\n",
       "       -0.16778696, -0.19443507,  0.08935329, -0.05819374, -0.01398199])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(Xs[1], hat_beta_1[1])[:10] + hat_beta_0[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8d4a1a78-aa68-4033-b966-34c40bc6f1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04385579,  0.07674032, -0.19366902,  0.25926723,  0.16030753,\n",
       "        0.20829929,  0.41353323,  0.25481849, -0.03864874,  0.3229477 ])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(Xs[1], hat_beta_share_1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "232550a5-5c89-4a23-8f0b-e8b1e92ecb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.  , -0.01, -0.  ,  0.06,  0.06, -0.03, -0.06,  0.01,  0.01,\n",
       "       -0.17, -0.  , -0.06,  0.12,  0.01,  0.  , -0.01,  0.06, -0.  ,\n",
       "       -0.02,  0.  ])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(Xs[1][0] * hat_beta_1[1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "87d38324-f76b-4971-a7ff-1bc3900dfd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.  , -0.01,  0.  ,  0.08,  0.25, -0.01,  0.07,  0.05, -0.  ,\n",
       "       -0.02,  0.03, -0.11,  0.25,  0.  ,  0.06, -0.  ,  0.06, -0.  ,\n",
       "       -0.  ,  0.01])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(Xs[1][1] * hat_beta_1[1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cd8f71c9-d1dd-4ba4-8e2a-62302789ce30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.  ,  0.16, -0.  , -0.11,  0.32, -0.26, -0.13,  0.06,  0.  ,\n",
       "       -0.15,  0.02, -0.05,  0.14, -0.03,  0.  , -0.01,  0.  , -0.  ,\n",
       "       -0.  ,  0.  ])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(Xs[1][2] * hat_beta_1[1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d9ad8347-f07f-4d78-bb64-b07cfdd915e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.   , 0.395, 0.395])]\n",
      "[array([0.   , 0.007, 0.007])]\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "for reg in ['new']:\n",
    "    ave, std = [], []\n",
    "    for N in [1000]:\n",
    "        ave.append(np.round(np.mean(output[N, reg], axis=0), 3))\n",
    "        std.append(np.round(np.std(output[N, reg], axis=0), 3))\n",
    "    \n",
    "    print(ave)\n",
    "    print(std)\n",
    "    print('---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fc58ce47-c526-4379-b38f-539a91686835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.21033974846151784,\n",
       " 0.2045690525646315,\n",
       " 0.20406218118372565,\n",
       " 0.2040151306404678,\n",
       " 0.20399770470721523,\n",
       " 0.20399656502463415,\n",
       " 0.20400452881424638,\n",
       " 0.20401754891506388,\n",
       " 0.20410221888823823,\n",
       " 0.20417803973383072,\n",
       " 0.20423744192267773,\n",
       " 0.20428378674692896,\n",
       " 0.20432053958677437,\n",
       " 0.20435024673885338,\n",
       " 0.2043746912612071,\n",
       " 0.204395126040309,\n",
       " 0.20449749571448775,\n",
       " 0.204535708603932]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_loss[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c97a49f8-0689-4ba3-b620-c7642877bd04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd9aac01278>]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0, 0.5, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 30]\n",
    "y = predict_loss[-1]\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b5cfcc-2b4d-4f66-af1d-683a2d8b6c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
